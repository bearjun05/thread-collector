# 스크래핑 정책 문서 (Threads Collector)

이 문서는 `thread-collector` 프로젝트에서 Threads 데이터를 수집할 때 적용되는 **스크래핑 흐름/제한/조기 종료(early stop) 정책**을 기록합니다.  
운영 중 성능 이슈나 “왜 이 지점에서 수집이 멈췄지?” 같은 질문이 나왔을 때, **코드의 의도와 안전장치**를 빠르게 확인하는 용도입니다.

---

## 1) 기본 원칙

- 이 프로젝트는 Threads의 공식 API가 아닌 **웹 페이지를 브라우저 자동화(Playwright)로 열어 DOM을 읽는 방식**을 사용합니다.
- 따라서 “서버에 날짜 조건을 전달해서 필요한 데이터만 내려받는” 형태가 아니라, **페이지를 스크롤하며 렌더링된 요소에서 `created_at`(time 태그)을 읽어 판단**합니다.
- 날짜 필터는 **정확도 보장을 위해 2중으로 동작**합니다.
  - **(A) 수집 중 조기 종료 최적화**: cutoff 이전 글이 연속으로 나오면 스크롤을 멈춰 시간을 절약
  - **(B) 수집 후 최종 날짜 필터링**: 결과 리스트에서 cutoff 조건으로 한 번 더 걸러 정확도 확보

---

## 2) cutoff(기간) 의미와 계산 방식

프로젝트 전반에서 cutoff는 **UTC 기준의 timezone-aware datetime**으로 취급합니다.

- `since_date`가 있으면 **since_days보다 우선**합니다.
  - `since_date`가 timezone 정보가 없는 문자열이면, **KST(UTC+9)로 해석**한 뒤 UTC로 변환합니다.
- `since_days`는 “오늘 기준 N일 전”을 의미하며, **UTC now - N days**로 cutoff를 계산합니다.

즉, 아래와 같은 의미를 갖습니다.

- `created_at >= cutoff_utc` 인 게시물만 “기간 내 게시물”로 간주

---

## 3) 프로필 스크래핑 조기 종료(early stop) 정책

### 3.1 정책이 적용되는 위치

- 대상 함수: `scraper.py`의 `scrape_threads_profile()`
- 적용 조건: `cutoff_utc` 인자가 **전달된 경우에만** 조기 종료가 동작합니다.

`app.py`의 `GET /scrape`, `POST /scrape`, `POST /scrape-with-replies`, 내부 배치 스크랩 경로는  
요청 파라미터(`since_days`, `since_date`)로 cutoff를 계산한 뒤 `cutoff_utc`로 전달합니다.

### 3.2 조기 종료 트리거 조건(현재 값)

조기 종료는 아래 조건을 **모두 만족**할 때 트리거됩니다.

- **최소 스크롤 보장**: 최소 5 라운드 이후에만 조기 종료 판단 (`MIN_SCROLL_ROUNDS = 5`)
  - 이유: pinned 게시물/초기 로딩 상태로 인해 최신 글이 아래쪽에 있을 수 있어, 너무 빨리 끊으면 누락 가능성이 커짐
- **최소 수집량 보장**: 수집 결과가 10개 이상일 때만 조기 종료 판단 (`len(results) >= 10`)
  - 이유: 표본이 너무 적을 때의 오판(우연히 오래된 글이 먼저 잡히는 경우)을 완화
- **연속 오래된 글 감지**: cutoff 이전 글이 연속 6개 이상이면 종료
  - 기준 값: `cutoff_old_streak_threshold = 6`
  - 정의: 각 게시물의 `created_at`을 파싱해서 `created_dt < cutoff_utc`이면 `old_post_streak += 1`  
    그렇지 않으면 `old_post_streak = 0` 으로 리셋

정리하면:

> “최소 5번은 스크롤했고, 최소 10개는 모은 상태에서, cutoff 이전 글이 6개 연속으로 나오면  
> 더 아래는 대부분 오래된 글일 가능성이 높으므로 스크롤을 멈춘다”

### 3.3 주의점(정확도/성능 트레이드오프)

- 이 정책은 **성능 최적화**이며, 엄밀히 100% 누락이 없음을 보장하진 않습니다.
- 누락 가능성을 줄이기 위해:
  - 최소 스크롤/최소 수집량 조건을 두었고,
  - 최종 응답 전에 `filter_posts_by_date`로 한 번 더 필터링하여 **“포함되면 안 되는 글”**이 섞이는 문제를 막습니다.

---

## 4) 답글(스레드) 수집 관련 정책 (참고)

- 개별 스레드 수집(`scrape_thread_with_replies`)은
  - “답글 더 보기” 클릭 및 스크롤을 통해 답글을 로드한 뒤,
  - 추천/관련 섹션이 감지되면 스크롤을 중단하여 노이즈를 줄입니다.
- 또한 현재 구현은 **원 게시물 작성자와 동일한 author의 답글만 포함**하는 필터링이 존재합니다.
  - 목적: 추천/관련 게시물 및 타 사용자 답글로 인한 노이즈 최소화
  - 주의: “모든 사용자 답글을 전부 수집”하는 요구에는 맞지 않을 수 있음

---

## 5) 운영 중 체크리스트

- “왜 수집이 빨리 끝났지?”  
  - cutoff가 전달되었고(기간 파라미터 존재), 최근 글이 적어 **연속 6개 cutoff 이전**이 빨리 발생했을 수 있습니다.
- “최근 글이 누락되는 것 같다”  
  - pinned 글이 많거나, DOM 순서가 비정상인 계정에서 조기 종료가 과하게 걸릴 수 있습니다.  
    이런 경우 `MIN_SCROLL_ROUNDS`, `cutoff_old_streak_threshold`, `len(results) >= 10` 같은 보수 조건을 조정해야 합니다.

---

## 6) 변경 이력

- 2025-12-13: 프로필 스크래핑에 cutoff 기반 조기 종료(early stop) 정책 추가 및 API 경로에 전파


